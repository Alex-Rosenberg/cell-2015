{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/gs/vol3/software/modules-sw-python/2.7.3/pandas/0.14.0/Linux/RHEL6/x86_64/lib/python2.7/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
      "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import scipy.stats\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import dnatools\n",
    "from MLR import MLR\n",
    "%matplotlib inline\n",
    "from pylab import *\n",
    "\n",
    "# Plotting Params:\n",
    "rc('mathtext', default='regular')\n",
    "fsize=14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make directory to save results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultsdir = '../results/N6_A5SS_Model_Learning_Curves/'\n",
    "if not os.path.exists(resultsdir):\n",
    "    os.makedirs(resultsdir)\n",
    "figdir = '../figures/N6_A5SS_Model_Learning_Curves/'\n",
    "if not os.path.exists(figdir):\n",
    "    os.makedirs(figdir)\n",
    "    \n",
    "#Choose if you want to actually save the plots:\n",
    "SAVEFIGS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sio.loadmat('../data/Reads.mat')\n",
    "# A5SS\n",
    "A5SS_data = data['A5SS']\n",
    "A5SS_reads = np.array(A5SS_data.sum(1)).flatten()\n",
    "A5SS_data = np.array(A5SS_data.todense())\n",
    "# Get minigenes with reads\n",
    "A5SS_nn = find(A5SS_data.sum(axis=1))\n",
    "A5SS_reads = A5SS_reads[A5SS_nn]\n",
    "A5SS_data = A5SS_data[A5SS_nn]\n",
    "A5SS_data = A5SS_data/A5SS_data.sum(axis=1)[:,newaxis]\n",
    "A5SS_seqs = pd.read_csv('../data/A5SS_Seqs.csv',index_col=0).Seq[A5SS_nn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get n-mer counts within each randomized region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have written a function that return the counts of each n-mer within a sequence. With n minigenes the resulting matrix will be (n x $4^k$), for n-mers of length k. I make a matrix for each randomized region and then combine the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000 220000 230000 240000 250000 260000 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000 220000 230000 240000 250000 260000 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000 220000 230000 240000 250000 260000 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000 220000 230000 240000 250000 260000 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000 220000 230000 240000 250000 260000 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000 220000 230000 240000 250000 260000 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000 220000 230000 240000 250000 260000 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000 220000 230000 240000 250000 260000 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000 220000 230000 240000 250000 260000 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000 220000 230000 240000 250000 260000\n"
     ]
    }
   ],
   "source": [
    "R1 = A5SS_seqs.str.slice(7,32)\n",
    "R2 = A5SS_seqs.str.slice(50,75)\n",
    "X = {}\n",
    "for mer_len in range(3,8):\n",
    "    X_r1 = dnatools.make_mer_matrix_no_pos(R1,mer_len)\n",
    "    X_r2 = dnatools.make_mer_matrix_no_pos(R2,mer_len)\n",
    "    X[mer_len] = scipy.sparse.csr_matrix(scipy.sparse.hstack((X_r1,X_r2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target that we want to predict is the fraction of splicing at $SD_1$. Y is (n x 2) with the first column reprenting $1-p(SD_1$) and the second column $p(SD_1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = scipy.matrix(np.array((1-A5SS_data[:,0],A5SS_data[:,0])).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have already made split the data into training and test sets. This just loads the indices of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    inds = range(len(A5SS_seqs))\n",
    "    shuffle(inds)\n",
    "    train_set = inds[:int(len(inds)*0.9)]\n",
    "    test_set = inds[int(len(inds)*0.9):]\n",
    "else:\n",
    "    train_set = np.loadtxt(resultsdir+'training_inds').astype(int)\n",
    "    test_set = np.loadtxt(resultsdir+'test_inds').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the data sizes and values of lambda that we will test. We will only test L1 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_sizes = np.int64(10**arange(2,5.26,0.25))\n",
    "lambdas = 10**arange(-1,-9,-1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all of the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Lambda: 0.1\n",
      "-----------------mer_len: 3\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 4\n",
      "-----------------Data Size: 100 Failed to converge...\n",
      "177 Failed to converge...\n",
      "316 Failed to converge...\n",
      "562 Failed to converge...\n",
      "1000 Failed to converge...\n",
      "1778 Failed to converge...\n",
      "3162 Failed to converge...\n",
      "5623 Failed to converge...\n",
      "10000 Failed to converge...\n",
      "17782 Failed to converge...\n",
      "31622 Failed to converge...\n",
      "56234 Failed to converge...\n",
      "100000 Failed to converge...\n",
      "177827 Failed to converge...\n",
      "-----------------mer_len: 5\n",
      "-----------------Data Size: 100 Failed to converge...\n",
      "177 Failed to converge...\n",
      "316 Failed to converge...\n",
      "562 Failed to converge...\n",
      "1000 Failed to converge...\n",
      "1778 Failed to converge...\n",
      "3162 Failed to converge...\n",
      "5623 Failed to converge...\n",
      "10000 Failed to converge...\n",
      "17782 Failed to converge...\n",
      "31622 Failed to converge...\n",
      "56234 Failed to converge...\n",
      "100000 Failed to converge...\n",
      "177827 Failed to converge...\n",
      "-----------------mer_len: 6\n",
      "-----------------Data Size: 100 Failed to converge...\n",
      "177 Failed to converge...\n",
      "316 Failed to converge...\n",
      "562 Failed to converge...\n",
      "1000 Failed to converge...\n",
      "1778 Failed to converge...\n",
      "3162 Failed to converge...\n",
      "5623 Failed to converge...\n",
      "10000 Failed to converge...\n",
      "17782 Failed to converge...\n",
      "31622 Failed to converge...\n",
      "56234 Failed to converge...\n",
      "100000 Failed to converge...\n",
      "177827 Failed to converge...\n",
      "-----------------mer_len: 7\n",
      "-----------------Data Size: 100 Failed to converge...\n",
      "177 Failed to converge...\n",
      "316 Failed to converge...\n",
      "562 Failed to converge...\n",
      "1000 Failed to converge...\n",
      "1778 Failed to converge...\n",
      "3162 Failed to converge...\n",
      "5623 Failed to converge...\n",
      "10000 Failed to converge...\n",
      "17782 Failed to converge...\n",
      "31622 Failed to converge...\n",
      "56234 Failed to converge...\n",
      "100000 Failed to converge...\n",
      "177827 Failed to converge...\n",
      "-----------------Lambda: 0.01\n",
      "-----------------mer_len: 3\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 4\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 5\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 6\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 Failed to converge...\n",
      "17782 Failed to converge...\n",
      "31622 Failed to converge...\n",
      "56234 Failed to converge...\n",
      "100000 Failed to converge...\n",
      "177827 Failed to converge...\n",
      "-----------------mer_len: 7\n",
      "-----------------Data Size: 100 177 Failed to converge...\n",
      "316 Failed to converge...\n",
      "562 Failed to converge...\n",
      "1000 Failed to converge...\n",
      "1778 Failed to converge...\n",
      "3162 Failed to converge...\n",
      "5623 Failed to converge...\n",
      "10000 Failed to converge...\n",
      "17782 Failed to converge...\n",
      "31622 Failed to converge...\n",
      "56234 Failed to converge...\n",
      "100000 Failed to converge...\n",
      "177827 Failed to converge...\n",
      "-----------------Lambda: 0.001\n",
      "-----------------mer_len: 3\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 4\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 5\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 6\n",
      "-----------------Data Size: 100 177 Failed to converge...\n",
      "316 Failed to converge...\n",
      "562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 7\n",
      "-----------------Data Size: 100 177 316 Failed to converge...\n",
      "562 1000 1778 Failed to converge...\n",
      "3162 5623 10000 17782 31622 56234 100000 177827 -----------------Lambda: 0.0001\n",
      "-----------------mer_len: 3\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 4\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 5\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 6\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 7\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------Lambda: 1e-05\n",
      "-----------------mer_len: 3\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 4\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 5\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 6\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 7\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------Lambda: 1e-06\n",
      "-----------------mer_len: 3\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 4\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 5\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 6\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 7\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------Lambda: 1e-07\n",
      "-----------------mer_len: 3\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 4\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 5\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 6\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 7\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------Lambda: 1e-08\n",
      "-----------------mer_len: 3\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 177827 -----------------mer_len: 4\n",
      "-----------------Data Size: 100 177 316 562 1000 1778 3162 5623 10000 17782 31622 56234 100000 "
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for L in lambdas:\n",
    "    models[L] = {}\n",
    "    print '-----------------Lambda:',L\n",
    "    for mer_len in range(3,8):\n",
    "        models[L][mer_len] = {}\n",
    "        print '-----------------mer_len:',mer_len\n",
    "        sys.stdout.flush()\n",
    "        print '-----------------Data Size:',\n",
    "        for data_size in data_sizes:\n",
    "            print data_size,\n",
    "            models[L][mer_len][data_size] = MLR(verbose=False)\n",
    "            models[L][mer_len][data_size].fit(X[mer_len][train_set[:data_size]],\n",
    "                                              Y[train_set[:data_size]],\n",
    "                                              reg_type='L1',\n",
    "                                              reg_lambda=L,\n",
    "                                              maxit=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_preds = {}\n",
    "for L in lambdas:\n",
    "    model_preds[L] = {}\n",
    "    print '-----------------Lambda:',L\n",
    "    for mer_len in range(3,8):\n",
    "        model_preds[L][mer_len] = {}\n",
    "        print '-----------------mer_len:',mer_len\n",
    "        for data_size in data_sizes:\n",
    "            print data_size,\n",
    "            model_preds[L][mer_len][data_size] = models[L][mer_len][data_size].predict(X[mer_len][test_set])\n",
    "        print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(Y)[test_set,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R2s = {}\n",
    "for L in lambdas:\n",
    "    R2s[L] = {}\n",
    "    for mer_len in range(3,8):\n",
    "        R2s[L][mer_len] = {}\n",
    "        print '-----------------mer_len:',mer_len\n",
    "        for data_size in data_sizes:\n",
    "            R2s[L][mer_len][data_size] = scipy.stats.pearsonr(model_preds[L][mer_len][data_size][:,1],np.array(Y)[test_set,1])[0]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R2s = pd.Panel(R2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R2s.to_pickle(resultsdir+'Subsampling_R2.panel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#R2s = pd.read_pickle(resultsdir+'Subsampling_R2.panel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results (with the best L1 regularization parameter $\\lambda$ ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R2_maxes = R2s.apply(max,axis=0).iloc[:14]\n",
    "fig = figure(figsize=(9,4))\n",
    "ax = fig.add_subplot(111)\n",
    "markers = ['o','s','v','D','p']\n",
    "c = 0\n",
    "for col in R2_maxes.columns:\n",
    "    R2_maxes[col].plot(label=str(col)+'-mer',marker=markers[c])\n",
    "    c+=1\n",
    "#R2s.apply(max,axis=0).iloc[:14].plot(ax=ax,marker='o')\n",
    "ax.set_xscale('log')\n",
    "leg = legend([str(i)+'-mers' for i in range(3,8)],bbox_to_anchor=(1.25,1),numpoints=1,fontsize=fsize)\n",
    "leg.get_frame().set_alpha(0)\n",
    "leg.set_title('Features')\n",
    "ax.set_xlabel('Number of Training Points',fontsize=fsize)\n",
    "ax.set_ylabel('$R^2$',fontsize=fsize)\n",
    "setp(leg.get_title(),fontsize=fsize)\n",
    "ax.tick_params(labelsize=fsize)\n",
    "ax.set_xlim(90,200000)\n",
    "ax.set_title('A5SS Library Learning Curve ($SD_1$)',fontsize=fsize)\n",
    "if SAVEFIGS:\n",
    "    figname = 'A5SS_Learning_Curves'\n",
    "    fig.savefig(figdir+figname+'.png',bbox_inches='tight', dpi = 300)\n",
    "    fig.savefig(figdir+figname+'.pdf',bbox_inches='tight', dpi = 300)\n",
    "    fig.savefig(figdir+figname+'.eps',bbox_inches='tight', dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
