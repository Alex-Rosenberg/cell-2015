{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import scipy.stats\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import dnatools\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "from pylab import *\n",
    "# Plotting Params:\n",
    "rc('mathtext', default='regular')\n",
    "fsize=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultsdir = '../results/N0_A3SS_Fastq_to_Splice_Reads/'\n",
    "if not os.path.exists(resultsdir):\n",
    "    os.makedirs(resultsdir)\n",
    "figdir = '../figures/N0_A3SS_Fastq_to_Splice_Reads/'\n",
    "if not os.path.exists(figdir):\n",
    "    os.makedirs(figdir)\n",
    "    \n",
    "#Choose if you want to actually save the plots:\n",
    "SAVEFIGS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alt3SS_seq = '.........................GCTTGGATCTGATCTCAACAGGGT.........................'\n",
    "alt3SS_tag = 'CATTACCTGC.........................'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a map between 3'UTR barcodes and randomized intronic sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of dictionaries. Top level keys are the 3'UTR barcode sequences. For each barcode there is a counter dictionary, which counts the occurences of each intron sequence with that barcode. These sequences are only counted if the non-randomized regions match exactly to the plasmid sequence (no mis-matches or deletions). One sequence count is added from the forward read and another sequence count is added from the reverse read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 | 1000000 795826 | 2000000 1600187 | 3000000 2398971 | 4000000 3198607 | 5000000 3994250 | 6000000 4786859 | 7000000 5578120 | 8000000 6357719 | 9000000 7129306 | 10000000 7919234 | 11000000 8718215 | 12000000 9513516 | 13000000 10307821 | 14000000 11092251 | 15000000 11863855 | 16000000 12637931 | 17000000 13397479 | 18000000 14145314 |\n"
     ]
    }
   ],
   "source": [
    "f = {}\n",
    "f[0] = open('../fastq/A3SS_dna_R1.fq','r')\n",
    "f[1] = open('../fastq/A3SS_dna_R2.fq','r')\n",
    "tags = Counter()\n",
    "c = 0\n",
    "p = 0\n",
    "header = {}\n",
    "seq = {}\n",
    "strand = {}\n",
    "quality ={}\n",
    "tag_seqs = {}\n",
    "d = 0\n",
    "while True:\n",
    "    for i in range(2):\n",
    "        header[i] = f[i].readline()[:-1]\n",
    "        seq[i] = f[i].readline()[:-1]\n",
    "        strand[i] = f[i].readline()[:-1]\n",
    "        quality[i] = f[i].readline()[:-1]\n",
    "\n",
    "    cur_tag = dnatools.reverse_complement(seq[1])\n",
    "    if(len(header[0])==0):\n",
    "        break\n",
    "        \n",
    "    # Check passing reads and that the sequence after the random tag matches\n",
    "    # the plasmid sequence.\n",
    "    if (cur_tag[10:20]==alt3SS_tag[:10]):\n",
    "        p += 1\n",
    "        #Check that the non-randomized sequences match perfectly to the reference\n",
    "        if(seq[0][25:25+24]==alt3SS_seq[25:-25]):\n",
    "            d+=1\n",
    "            try:\n",
    "                tag_seqs[cur_tag]\n",
    "            except:\n",
    "                tag_seqs[cur_tag] = Counter()\n",
    "            tag_seqs[cur_tag][seq[0]]+=1\n",
    "\n",
    "    if(c%1000000)==0:\n",
    "        print c,p,'|',\n",
    "    c+=1\n",
    "    \n",
    "for i in range(2):\n",
    "    f[i].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each tag, I find the intron sequence that occurred the most times with that tag. I will only keep tag-sequence pairs that occurred at least twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100000 200000 300000 400000 500000 600000 700000 800000 900000 1000000 1100000 1200000 1300000 1400000 1500000 1600000 1700000 1800000 1900000 2000000 2100000 2200000 2300000 2400000 2500000 2600000 2700000 2800000 2900000 3000000 3100000 3200000 3300000 3400000 3500000 3600000 3700000 3800000 3900000 4000000 4100000 4200000 4300000\n"
     ]
    }
   ],
   "source": [
    "ks = tag_seqs.keys()\n",
    "tag_map = {}\n",
    "tag_map_counts = {}\n",
    "c = 0\n",
    "for k in ks:\n",
    "    max_seq = max(tag_seqs[k]) # Get seq\n",
    "    max_seq_counts = tag_seqs[k][max_seq]\n",
    "    if(max_seq_counts>=2):\n",
    "        tag_map[k] = max_seq\n",
    "        tag_map_counts[k] = max_seq_counts\n",
    "    if(c%100000)==0:\n",
    "        print c,\n",
    "    c+=1\n",
    "seq_series = pd.Series(tag_map)\n",
    "seq_counts = pd.Series(tag_map_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, I've kept 30nt of the barcode, even though only 20nt of that is randomized. Let's trim this to 20nt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_series = pd.Series(dict(zip(pd.Series(seq_series.index).str.slice(-20),seq_series.values )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the barcode-sequence mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_series.name='Seq'\n",
    "seq_series.index.name='Tag'\n",
    "seq_series.to_csv('../data/A3SS_Seqs.csv',index_label='Tag',header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the spliced reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dictionary to specifiy the row of each barcode in the read count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag2seq_dict = dict(zip(seq_series.index,arange(len(seq_series))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the sequence to which we will map reads. The first nucleotide corresponds the the first nucleotide (5') in the intron. I have included sequence in the second exon, in case downstream splice acceptors are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alt3SS_full_seq = 'gtaagttatcaccttcgtggctacagagtttccttatttgtctctgttgccggcttatatggacaagcatatcacagccatttatcggagcgcctccgtacacgctattatcggacgcctcgcgagatcaatacgtataccagctgccctcgatacatgtcttggacggggtcggtgttgatatcgtatNNNNNNNNNNNNNNNNNNNNNNNNNGCTTGGATCTGATCTCAACAGGGTNNNNNNNNNNNNNNNNNNNNNNNNNatgattacacatatagacacgcgagcacccatcttttatagaatgggtagaacccgtcctaaggactcagattgagcatcgtttgcttctcgagtactacctggtacagatgtctcttcaaacaggacggcagcgtgcagctcgccgaccactaccagcagaacacccccatcggcgacggccccgtgctgctgcccgacaaccactacctgagctaccagtccgccctgagcaaagaccccaacgagaagcgcgatcacatggtcctgctggagttcgtgaccgccgccgggatcactctcggcatggacgagctgtacaaggactgatagtaaggcccattacctgcNNNNNNNNNNNNNNNNNNNNGCAGAACACAGCGGTTCGACCTGCGTGATATCTCGTATGCCGTCTTCTGCTTG'\n",
    "alt3SS_full_seq = alt3SS_full_seq.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To map the position of the spliced exon-exon junction, I map the last 20 nt of the read. For example, if the read was spliced at the last SA (most 3'), then the 100-120 nt of the read will map 100-120 nt into the second exon. If the read was spliced 20nt 5' of the last SA, the 100-120 nt of the read will map 80-100 nt into the second exon. If there is no splicing, the 100-120 nt of the read will map within 100-120 nt into the intron. However, requiring an exact match for these 20 nt is very stringent and we may lose reads. So if there is no match in the 100-120 nt of the read, I then check for a match in the 80-100 nt of the read, and then finally the 60-80 nt of the read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000000 2000000 3000000 4000000 5000000 6000000 7000000 8000000 9000000 10000000 11000000 12000000 13000000 14000000 15000000 16000000\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "header = {}\n",
    "seq = {}\n",
    "strand = {}\n",
    "quality ={}\n",
    "\n",
    "tag_list = []\n",
    "ss_list = []\n",
    "\n",
    "f = {}\n",
    "f[0] = open('../fastq/A3SS_rna_R1.fq','r')\n",
    "f[1] = open('../fastq/A3SS_rna_R2.fq','r')\n",
    "\n",
    "while True:\n",
    "    for i in range(2):\n",
    "        header[i] = f[i].readline()[:-1]\n",
    "        seq[i] = f[i].readline()[:-1]\n",
    "        strand[i] = f[i].readline()[:-1]\n",
    "        quality[i] = f[i].readline()[:-1]\n",
    "    if(len(header[i])==0):\n",
    "        break\n",
    "        #min_qual[i] = min(quality[i])\n",
    "    tag = dnatools.reverse_complement(seq[1][:20])\n",
    "\n",
    "    try:\n",
    "        tag_ind = tag2seq_dict[tag]\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        # Check if the end of the read 100-120 matches the second exon\n",
    "        # of citrine. In case of mismatches, I check for matches to 3\n",
    "        # different 20nt regions.\n",
    "        s_start = alt3SS_full_seq.find(seq[0][100:120])-100\n",
    "        if(s_start<-100):\n",
    "            s_start = alt3SS_full_seq.find(seq[0][80:100])-80\n",
    "            if(s_start<-80):\n",
    "                s_start = alt3SS_full_seq.find(seq[0][60:80])-60\n",
    "        if(s_start>=0):\n",
    "            tag_list.append(tag_ind)\n",
    "            ss_list.append(s_start)\n",
    "    if(c%1000000)==0:\n",
    "        print c,\n",
    "    c+=1\n",
    "\n",
    "for i in range(2):\n",
    "    f[i].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the sparse matrix and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splices = {'A3SS':scipy.sparse.csr_matrix((list(np.ones_like(ss_list))+[0],\n",
    "                                           (tag_list+[len(seq_series)-1],ss_list+[565])),\n",
    "                                          dtype=np.float64)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sio.savemat('../data/A3SS_Reads.mat',splices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
